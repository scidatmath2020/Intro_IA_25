{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff39fe9",
   "metadata": {},
   "source": [
    "![imagenes](logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcce9c8b",
   "metadata": {},
   "source": [
    "# Regresión Lineal Simple y Múltiple en Machine Learning\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En el aprendizaje automático supervisado, una de las tareas más comunes es la predicción de una variable continua a partir de una o más variables de entrada. Este tipo de problema se conoce como regresión, y uno de los métodos más conocidos, clásicos y aún vigentes por su simplicidad y poder explicativo es la regresión lineal.\n",
    "\n",
    "En este capítulo exploraremos la regresión lineal simple y múltiple desde el punto de vista del aprendizaje automático, haciendo énfasis no solo en su formulación matemática, sino en su interpretación práctica, los supuestos que la sustentan, las métricas para evaluarla, y sus usos y limitaciones. A lo largo del texto se presentarán ejemplos implementados en Python utilizando la biblioteca scikit-learn, una de las más utilizadas para tareas de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29de454",
   "metadata": {},
   "source": [
    "## Geometría analítica\n",
    "\n",
    "Antes de avanzar, recordemos nuestros cursos de Geometría Analítica: toda recta en el plano es una ecuación de la forma $$y=mx+b$$ donde \n",
    "\n",
    "* $b$ se conoce como *ordenada al origen* y es el valor sobre el eje Y en que en la recta lo atraviesa. En regresión lineal se le llama *intercepto*.\n",
    "\n",
    "* $m$ se conoce como *pendiente de la recta* y se identifica como la tangente inversa del ángulo que hace la recta con el eje X. En cristiano: $m$ mide la inclinación de la recta. También en regresión lineal se llama pendiente. Si $m>0$ la recta va hacia arriba; si $m<0$ la recta va hacia abajo; si $m=0$, la recta es horizontal.\n",
    "\n",
    "Observa la interacción del archivo **geogebra-recta_pendiente_origen.ggb** de nuestro repositoria [que mostramos aquí con GeoGebra](https://github.com/scidatmath2020/Inferencia-Estad-stica-2022/blob/main/geogebra-recta_pendiente_origen.ggb)\n",
    "\n",
    "Por lo tanto, **hallar la ecuación de una recta equivale a hallar los valores de $m$ y $b$**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919bbcd8",
   "metadata": {},
   "source": [
    "Observemos la siguiente nube de puntos: \n",
    "\n",
    "![imagenes](im006.png)\n",
    "\n",
    "Debido a su forma, vale preguntarse cuál será la recta que mejor se aproxime, en algún sentido, a todos los puntos al mismo tiempo.\n",
    "\n",
    "Observemos varias rectas graficadas con la nube de puntos. ¿Cuál dirías que es la que más se *ajusta* a todos los puntos al mismo tiempo?\n",
    "\n",
    "![imagenes](im007.png)\n",
    "\n",
    "De esta manera, sean $X$ y $Y$ dos características de tu población. Decimos que el modelo que explica a $Y$ a través de $X$ es lineal si tenemos razones para pensar que existen números $B_0$ y $B_1$ tales que $y=B_0+B_1x+\\varepsilon$ donde es una influencia totalmente aleatoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed93d46",
   "metadata": {},
   "source": [
    "## ¿Qué es la regresión lineal?\n",
    "\n",
    "La regresión lineal es un modelo que intenta establecer una relación matemática entre una o más variables independientes (también llamadas features o atributos) y una variable dependiente o objetivo. El objetivo principal es ajustar una función lineal que permita predecir el valor de la variable dependiente a partir de los valores de las independientes.\n",
    "\n",
    "Esta técnica se remonta a siglos atrás en estadística, pero hoy sigue teniendo un papel central en modelos predictivos por su capacidad de interpretar y explicar relaciones entre variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33b2cbd",
   "metadata": {},
   "source": [
    "# Regresión lineal simple\n",
    "\n",
    "La regresión lineal simple estudia el caso en que hay solo una variable predictora $x$ y una variable a predecir $y$. Su modelo es una línea recta en el plano cartesiano:\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 x$$\n",
    "\n",
    "Aquí:\n",
    "\n",
    "- $\\beta_0$ es el intercepto (valor de $y$ cuando $x=0$),\n",
    "- $\\beta_1$ es la pendiente de la recta, y\n",
    "- $\\hat{y}$ es el valor estimado de la variable respuesta.\n",
    "\n",
    "Este modelo asume que, si representamos los puntos de datos en un gráfico, todos deberían alinearse (más o menos) a lo largo de una recta. La distancia entre los puntos observados y la recta corresponde al error o residuo, que idealmente debería ser pequeño."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf56433",
   "metadata": {},
   "source": [
    "Geométricamente, en esta situación solo tenemos dos columnas, por lo que podemos hacer una visualización del modelo:\n",
    "\n",
    "![imagenes](im009.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb0306",
   "metadata": {},
   "source": [
    "## Regresión Lineal Múltiple\n",
    "\n",
    "Cuando la variable de interés depende de más de un factor, el modelo se generaliza a la regresión lineal múltiple. En este caso, la predicción depende de varias variables $x_1,\\,x_2,\\,...,\\,x_p$ y el modelo adopta la forma:\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p$$\n",
    "\n",
    "Cada coeficiente $\\beta_i$ representa el cambio esperado en $y$ cuando $x_i$ cambia en una unidad, manteniendo constantes las demás variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a94386",
   "metadata": {},
   "source": [
    "## Implementación en Python\n",
    "\n",
    "### El dataset Advertising.csv\n",
    "#### https://github.com/scidatmath2020/Intro_IA_25/blob/main/datos/Advertising.csv\n",
    "\n",
    "Este conjunto de datos proviene del libro \"An Introduction to Statistical Learning\" (ISLR), un texto ampliamente utilizado en cursos universitarios sobre estadística y machine learning. Fue creado para analizar el efecto de distintas formas de publicidad en las ventas de un producto.\n",
    "\n",
    "Contiene información de una campaña publicitaria realizada en distintos mercados regionales (200 en total). Para cada mercado se registraron\n",
    "\n",
    "| Variable    | Descripción                                                               |\n",
    "| ----------- | ------------------------------------------------------------------------- |\n",
    "| `TV`        | Dinero invertido en publicidad televisiva (en miles de dólares)           |\n",
    "| `Radio`     | Dinero invertido en publicidad radial (en miles de dólares)               |\n",
    "| `Newspaper` | Dinero invertido en publicidad impresa (periódicos) (en miles de dólares) |\n",
    "| `Sales`     | Ventas del producto en ese mercado (en miles de unidades)                 |\n",
    "\n",
    "Cada renglón no representa un producto ni una marca, sino una región geográfica o mercado local en el que se midió el efecto de distintas estrategias publicitarias. Específicamente, cada fila representa un mercado regional (por ejemplo, una ciudad o zona de ventas), donde se ejecutó una campaña publicitaria de un mismo producto, con una cierta combinación de gasto en TV, radio y periódicos, y se midieron las ventas obtenidas en ese mercado.\n",
    "\n",
    "Imagina que una empresa vende el mismo producto en 200 ciudades distintas. En cada ciudad decide invertir diferentes cantidades en TV, radio y periódico. Luego mide cuántas unidades del producto se vendieron. Cada fila del dataset es una ciudad, y lo que queremos saber es: ¿cómo se relaciona el tipo de publicidad con las ventas obtenidas?\n",
    "\n",
    "### El dataset mpg.csv \n",
    "#### https://github.com/scidatmath2020/Intro_IA_25/blob/main/datos/mpg.csv\n",
    "\n",
    "El dataset Auto MPG (Millas Por Galón) proviene de la base de datos de la UCI Machine Learning Repository y fue recolectado originalmente por la Agencia de Protección Ambiental de EE. UU. (EPA) en colaboración con la revista Motor Trend. Cada renglón representa un automóvil específico (marca, modelo y año) con sus respectivas especificaciones técnicas.\n",
    "\n",
    "Fue creado para analizar y comparar la eficiencia de combustible de distintos modelos de automóviles fabricados entre 1970 y 1982, una época de gran interés por el consumo energético debido a las crisis petroleras.\n",
    "\n",
    "El objetivo es predecir el consumo de combustible (en millas por galón, mpg) de un automóvil a partir de sus características físicas y técnicas.\n",
    "\n",
    "| Columna        | Tipo       | Descripción                                                                 |\n",
    "| -------------- | ---------- | --------------------------------------------------------------------------- |\n",
    "| `mpg`          | Numérica   | **Rendimiento de combustible** en millas por galón (objetivo de predicción) |\n",
    "| `cylinders`    | Entera     | Número de cilindros del motor                                               |\n",
    "| `displacement` | Numérica   | Cilindrada del motor (en pulgadas cúbicas)                                  |\n",
    "| `horsepower`   | Numérica   | Potencia del motor (en caballos de fuerza)                                  |\n",
    "| `weight`       | Numérica   | Peso del automóvil (en libras)                                              |\n",
    "| `acceleration` | Numérica   | Tiempo en segundos para acelerar de 0 a 60 mph                              |\n",
    "| `model_year`   | Entera     | Año del modelo (por ejemplo, 76 = 1976)                                     |\n",
    "| `origin`       | Categórica | Región de origen: 1 = USA, 2 = Europa, 3 = Japón                            |\n",
    "| `name`         | Texto      | Nombre del modelo (marca + modelo + versión)                                |\n",
    "\n",
    "#### Modelos sugeridos para el dataset Auto MPG\n",
    "\n",
    "Este dataset contiene especificaciones técnicas de automóviles fabricados entre 1970 y 1982, y su consumo de combustible expresado en millas por galón (`mpg`). El objetivo es predecir `mpg` a partir de distintas variables.\n",
    "\n",
    "##### Modelos de regresión lineal simple\n",
    "\n",
    "1. **`mpg ~ horsepower`**  \n",
    "   A mayor potencia del motor, menor eficiencia de combustible. Relación negativa clara.\n",
    "\n",
    "2. **`mpg ~ weight`**  \n",
    "   Los autos más pesados consumen más combustible. Modelo simple y altamente explicativo.\n",
    "\n",
    "3. **`mpg ~ acceleration`**  \n",
    "   Menor influencia directa, pero útil para explorar si vehículos más ágiles consumen más o menos.\n",
    "\n",
    "4. **`mpg ~ model_year`**  \n",
    "   Relación positiva: los modelos más recientes tienden a ser más eficientes debido a avances tecnológicos.\n",
    "\n",
    "\n",
    "\n",
    "##### Modelos de regresión lineal múltiple\n",
    "\n",
    "1. **Modelo mecánico básico:**\n",
    "   $$\n",
    "   mpg \\sim horsepower + weight + displacement\n",
    "   $$\n",
    "   \n",
    "   Combina variables técnicas clave: potencia, masa y tamaño del motor.\n",
    "---\n",
    "2. **Modelo extendido:**\n",
    "   $$\n",
    "   mpg \\sim horsepower + weight + displacement + acceleration + model\\_year\n",
    "   $$\n",
    "   \n",
    "   Añade variables relacionadas con diseño y tecnología.\n",
    "\n",
    "---\n",
    "3. **Modelo completo:**\n",
    "   $$\n",
    "   mpg \\sim cylinders + horsepower + weight + displacement + acceleration + model\\_year + origin\n",
    "   $$\n",
    "   \n",
    "   Utiliza casi todas las variables del dataset.\n",
    "\n",
    "---\n",
    "\n",
    "Estos modelos permiten explorar cómo diferentes características técnicas y de diseño afectan el rendimiento de los vehículos, y son ideales para ilustrar conceptos clave de la regresión lineal tanto simple como múltiple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48e7356",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#################### Carga de módulos de Python ########################\n",
    "########################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from plotnine import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8209e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "############ Lectura de archivo y preprocesamiento de datos ############\n",
    "########################################################################\n",
    "\n",
    "### Dirigirse a la carpeta donde está tu tabla si es que no estás trabajando en línea\n",
    "#os.chdir(r\"ruta\")\n",
    "os.chdir(r\"C:\\Users\\Usuario\\Documents\\scidata\\25_Intro_IA\")\n",
    "\n",
    "#mi_tabla = pd.read_csv(\"mi_tabla.csv\") \n",
    "mi_tabla = pd.read_csv(\"Advertising.csv\")\n",
    "#mi_tabla = pd.read_csv(\"mpg.csv\")\n",
    "\n",
    "dataset = mi_tabla.select_dtypes(np.number)\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf468fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Supongamos que la columna objetivo se llama Co y las variables independientes se llaman C1,C2,...,Cn.\n",
    "\n",
    "## Variable objetivo\n",
    "#nombre_variable_objetivo = \"Co\"  # esta linea se debe modificar a tu necesidad: \n",
    "nombre_variable_objetivo = \"sales\"\n",
    "#nombre_variable_objetivo = \"mpg\"\n",
    "\n",
    "objetivo = dataset[nombre_variable_objetivo]\n",
    "\n",
    "## Variable(s) independiente(s)\n",
    "\n",
    "#variables_independientes = dataset[[\"C1\",\"C2\",...,\"Cn\"]] \n",
    "variables_independientes = dataset.drop(columns=nombre_variable_objetivo) \n",
    "#variables_independientes = dataset[[\"horsepower\",\"weight\",\"displacement\"]] \n",
    "#variables_independientes = dataset.drop(columns=nombre_variable_objetivo)\n",
    "# variables_independientes = dataset.drop(columns=[nombres de las columnas que quieres quitar],errors='ignore')\n",
    "\n",
    "nombre_variables_independientes = variables_independientes.columns\n",
    "nombre_variables_independientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fdbc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "########################   Ajuste del modelo   #########################\n",
    "########################################################################\n",
    "\n",
    "####### División en entrenamiento y prueba con 20% de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(variables_independientes, objetivo, test_size=0.2,random_state=42)\n",
    "\n",
    "# Construye el pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"imputacion\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"modelo\", LinearRegression())\n",
    "])\n",
    "\n",
    "# Entrena el modelo con X_train y y_train\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Extrae el modelo entrenado (etapa final del pipeline)\n",
    "mi_modelo = pipeline.named_steps[\"modelo\"]\n",
    "\n",
    "coeficientes = pd.DataFrame({\n",
    "    \"Variable\": [\"Intercepto\"] + list(variables_independientes.columns),\n",
    "    \"Coeficiente\": [mi_modelo.intercept_] + list(mi_modelo.coef_)\n",
    "})\n",
    "\n",
    "print(coeficientes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62cc70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "##########################   Modelo final   ############################\n",
    "########################################################################\n",
    "\n",
    "texto_modelo = f\"{nombre_variable_objetivo} predicho = {coeficientes.Coeficiente[0]:.3f}\"\n",
    "\n",
    "for x in range(1,coeficientes.shape[0]):\n",
    "    signo = \" + \" if coeficientes.Coeficiente[x] >= 0 else \" - \"\n",
    "    texto_modelo = texto_modelo + f\"{signo}{np.abs(coeficientes.Coeficiente[x]):.3f} {coeficientes.Variable[x]}\"\n",
    "\n",
    "print(f\"El modelo es\\n\\n {texto_modelo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7e3f70",
   "metadata": {},
   "source": [
    "### Gráfica en regresión lineal simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_reales = dataset[[nombre_variables_independientes[0],nombre_variable_objetivo]]\n",
    "\n",
    "(ggplot(data=datos_reales) +\n",
    "    geom_point(mapping=aes(x=datos_reales.columns[0],y=datos_reales.columns[1]),color=\"blue\") +\n",
    "    geom_smooth(mapping=aes(x=datos_reales.columns[0],y=datos_reales.columns[1]),method=\"lm\",color=\"red\",se=False) \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd928a49",
   "metadata": {},
   "source": [
    "# Predicciones en datos desconocidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876bb2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supongamos que queremos hallar las predicciones en la tabla mis_nuevos_datos.csv\n",
    "\n",
    "columnas_entrenamiento = list(variables_independientes.columns)\n",
    "nuevos_datos = pd.read_csv(\"Advertising_desconocidos.csv\")\n",
    "#nuevos_datos = pd.read_csv(\"mpg_desconocidos.csv\")\n",
    "\n",
    "nuevos_datos[columnas_entrenamiento]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec63b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir_nuevos_datos(modelo_pipeline, nuevos_datos, columnas_entrenamiento):\n",
    "    \"\"\"\n",
    "    Realiza predicciones sobre nuevos datos usando un modelo entrenado.\n",
    "\n",
    "    Parámetros:\n",
    "    - modelo_pipeline: objeto de modelo entrenado.\n",
    "    - nuevos_datos: DataFrame con los nuevos casos a predecir.\n",
    "    - columnas_entrenamiento: lista con los nombres de columnas usadas para entrenar el modelo.\n",
    "\n",
    "    Devuelve:\n",
    "    - Un array con las predicciones.\n",
    "    \"\"\"\n",
    "    # Verifica si faltan columnas\n",
    "    columnas_faltantes = set(columnas_entrenamiento) - set(nuevos_datos.columns)\n",
    "    if columnas_faltantes:\n",
    "        raise ValueError(f\"Faltan columnas necesarias: {columnas_faltantes}\")\n",
    "\n",
    "    # Verifica si hay columnas adicionales\n",
    "    columnas_adicionales = set(nuevos_datos.columns) - set(columnas_entrenamiento)\n",
    "    if columnas_adicionales:\n",
    "        print(f\"Advertencia: se ignorarán columnas adicionales: {columnas_adicionales}\")\n",
    "\n",
    "    # Reordenar columnas para que coincidan con el modelo\n",
    "    nuevos_datos_ordenado = nuevos_datos[columnas_entrenamiento]\n",
    "\n",
    "    # Realizar predicción\n",
    "    return modelo_pipeline.predict(nuevos_datos_ordenado)\n",
    "\n",
    "predicciones_nuevos_datos = predecir_nuevos_datos(pipeline, nuevos_datos, columnas_entrenamiento)\n",
    "\n",
    "predicciones_df = pd.DataFrame(predicciones_nuevos_datos, columns=[\"Predicción\"])\n",
    "nuevos_con_prediccion = pd.concat([nuevos_datos.reset_index(drop=True), predicciones_df], axis=1)\n",
    "\n",
    "# Mostrar resultado\n",
    "nuevos_con_prediccion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d03b0e",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo\n",
    "\n",
    "Una vez que se entrena un modelo de regresión, es esencial evaluar qué tan bien predice. Para ello, se utilizan diversas métricas que nos permiten cuantificar el error entre las predicciones del modelo y los valores reales.\n",
    "Para evaluar un modelo de regresión, utilizamos métricas como:\n",
    "\n",
    "- MAE (Error absoluto medio)\n",
    "- MSE (Error cuadrático medio)\n",
    "- RMSE (Raíz del error cuadrático medio)\n",
    "- $R^2$ (coeficiente de determinación)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edf0eaf",
   "metadata": {},
   "source": [
    "---\n",
    "### Error absoluto medio (MAE)\n",
    "\n",
    "El MAE calcula el promedio de los errores absolutos:\n",
    "\n",
    "$$MAE=\\frac{1}{n}\\sum_{i=1}^n|y_i-\\hat{y_i}|$$\n",
    "\n",
    "Es fácil de interpretar: nos dice, en promedio, cuántas unidades estamos fallando en nuestras predicciones.\n",
    "\n",
    "#### ¿Qué significa esto en términos prácticos?\n",
    "\n",
    "Imagina que estás usando un modelo para predecir el precio de casas. Si el MAE resulta ser 20,000, eso significa que, en promedio, el modelo se equivoca por 20,000 unidades monetarias (por ejemplo, pesos o dólares) al estimar el precio de una casa.\n",
    "\n",
    "Una gran ventaja del MAE es que **conserva las unidades originales del problema**, lo que facilita mucho su interpretación para usuarios no técnicos. No tienes que elevar al cuadrado los errores ni sacar raíces: simplemente ves, en promedio, cuánto te estás equivocando.\n",
    "\n",
    "#### ¿Por qué se usa el valor absoluto?\n",
    "\n",
    "Porque nos interesa el tamaño del error, no si nos equivocamos por arriba o por abajo. Si un modelo predice 10 unidades de más en un caso y 10 de menos en otro, su error medio sin valor absoluto sería 0 —lo cual engañosamente sugeriría un modelo perfecto. Usando el valor absoluto, ambos errores cuentan por igual y no se cancelan entre sí.\n",
    "\n",
    "#### Fortalezas del MAE:\n",
    "\n",
    "- Fácil de interpretar.\n",
    "- Robusto frente a valores atípicos extremos (más robusto que el RMSE, por ejemplo).\n",
    "- No amplifica los errores grandes, los trata igual que los pequeños (lo cual puede ser bueno o malo, según el caso).\n",
    "\n",
    "#### ¿Cuándo conviene usar el MAE?\n",
    "\n",
    "- Cuando quieres una métrica directamente interpretable en las unidades del problema.\n",
    "\n",
    "- Cuando no quieres penalizar fuertemente los errores grandes, como sí lo haría el RMSE.\n",
    "\n",
    "- En contextos donde los errores simétricos tienen el mismo impacto económico o práctico (por ejemplo, subestimar o sobrestimar por la misma cantidad tiene el mismo costo).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e4ecfd",
   "metadata": {},
   "source": [
    "### Error cuadrático medio (MSE)\n",
    "\n",
    "El MSE eleva los errores al cuadrado antes de promediarlos:\n",
    "\n",
    "$$MSE=\\frac{1}{n}\\sum_{i=1}^n|y_i-\\hat{y_i}|^2$$\n",
    "\n",
    "#### ¿Qué nos dice el MSE?\n",
    "\n",
    "El MSE nos indica cuánto error cuadrático, en promedio, comete el modelo al hacer predicciones. Al elevar las diferencias al cuadrado, los errores negativos dejan de compensar a los positivos, y además se da más peso a los errores grandes que a los pequeños.\n",
    "\n",
    "Es decir, si el modelo se equivoca por 10 en un caso y por 100 en otro:\n",
    "- Con MAE, ambos errores se suman linealmente: $10+100=110$\n",
    "- Con MSE, se suman cuadráticamente: $10^2+100^2=10,100$\n",
    "\n",
    "Esto significa que el MSE amplifica el impacto de los errores grandes, lo cual es útil cuando queremos que el modelo “tema” equivocarse demasiado.\n",
    "\n",
    "#### ¿Cuáles son sus unidades?\n",
    "\n",
    "Aquí es importante ser cuidadoso. A diferencia del MAE y del RMSE, el MSE no conserva las unidades originales del problema. Si estamos prediciendo precios en pesos, el MSE estará expresado en pesos al cuadrado. Esto puede dificultar su interpretación directa, y por eso muchas veces se prefiere reportar el RMSE (la raíz del MSE), que sí tiene unidades interpretables.\n",
    "\n",
    "#### Ventajas del MSE:\n",
    "\n",
    "- Muy útil para optimización matemática: su derivada es suave, lo cual facilita el uso de algoritmos como gradiente descendente.\n",
    "- Penaliza fuertemente los errores grandes, ayudando a entrenar modelos que se cuidan de cometer predicciones muy erróneas.\n",
    "- Es la función de pérdida estándar para regresión en muchos algoritmos, como redes neuronales y regresión lineal clásica.\n",
    "\n",
    "#### Desventajas:\n",
    "\n",
    "- Su interpretación no es tan directa como la del MAE o RMSE, por el tema de las unidades al cuadrado.\n",
    "- Muy sensible a outliers, ya que los errores grandes afectan muchísimo el resultado.\n",
    "\n",
    "#### ¿Cuándo conviene usar el MSE?\n",
    "\n",
    "- Cuando estás en la etapa de entrenamiento de modelos, ya que el MSE se usa frecuentemente como función de costo a minimizar.\n",
    "- Cuando quieres que el modelo sea conservador respecto a los errores grandes.\n",
    "- Cuando el objetivo principal es la precisión en promedio, y no tanto la facilidad de interpretación.\n",
    "\n",
    "**Nota.** Cuando decimos que un modelo es conservador respecto a los errores grandes, nos referimos a que el modelo, durante el entrenamiento, hará lo posible por evitar cometer errores grandes, incluso si eso implica cometer más errores pequeños.\n",
    "\n",
    "Esto ocurre porque el MSE penaliza los errores grandes de forma cuadrática, es decir, mucho más fuerte que los errores pequeños. Matemáticamente:\n",
    "- Un error de 1 se traduce en una penalización de $1^2=1$\n",
    "- Un error de 10 se traduce en una penalización de $10^2=100$\n",
    "- Un error de 100 se traduce en una penalización de $100^2=10,000$\n",
    "\n",
    "Entonces, para minimizar el MSE, el modelo \"aprende\" que equivocarse por 100 es 10,000 veces peor que equivocarse por 1. Como consecuencia, el modelo tiende a ajustarse más en las zonas donde podría cometer errores grandes, siendo más “conservador” o “precavido” en esas regiones del espacio de entrada.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146ae15c",
   "metadata": {},
   "source": [
    "### Raíz del error cuadrático medio (RMSE)\n",
    "\n",
    "La RMSE es simplemente la raíz cuadrada del MSE. Esto permite que la métrica esté en la misma unidad que $y$ haciéndola más interpretable: $$RMSE=\\sqrt{MSE}$$\n",
    "\n",
    "#### ¿Qué representa el RMSE?\n",
    "\n",
    "El RMSE se interpreta como el error típico o estándar que comete el modelo, pero con una característica importante: penaliza los errores grandes más que los pequeños, ya que primero se elevan al cuadrado (como en el MSE), y solo al final se toma la raíz cuadrada para volver a las unidades originales del problema.\n",
    "\n",
    "En palabras más sencillas: *El RMSE te dice \"más o menos cuánto\" se equivoca el modelo en promedio, dando más peso a las predicciones que fallan mucho.*\n",
    "\n",
    "#### ¿Por qué tomar la raíz?\n",
    "Porque el MSE nos da un valor en unidades al cuadrado, lo cual no es fácil de interpretar.\n",
    "\n",
    "Por ejemplo, si estás prediciendo temperaturas en grados Celsius, el MSE está en $(^\\circ C)^2$.\n",
    "\n",
    "El RMSE corrige esto sacando la raíz cuadrada del MSE, devolviéndonos un número en grados Celsius, es decir, en las mismas unidades que los datos originales, igual que el MAE.\n",
    "\n",
    "Entonces:\n",
    "\n",
    "- El MAE nos dice: “En promedio, ¿cuánto me estoy equivocando?”\n",
    "\n",
    "- El RMSE nos dice: “En promedio (ponderado), ¿cuánto me estoy equivocando, considerando que los errores grandes son peores?”\n",
    "\n",
    "#### ¿Cuándo usar el RMSE?\n",
    "\n",
    "- Cuando los errores grandes son especialmente costosos y deben ser castigados más.\n",
    "\n",
    "- Cuando necesitas una métrica interpretable (como el MAE), pero con mayor sensibilidad a errores extremos.\n",
    "\n",
    "- Cuando estás comparando modelos y te interesa identificar cuál reduce mejor los errores más severos\n",
    "\n",
    "#### Una analogía útil \n",
    "\n",
    "Piensa en un profesor calificando a estudiantes. Si usara MAE, evaluaría todos los errores por igual: equivocarse en una pregunta difícil o fácil cuenta lo mismo.\n",
    "\n",
    "Pero si usa RMSE, entonces los errores más grandes (respuestas totalmente erróneas) tienen mucho más peso, y afectan más la calificación final. Es como un sistema de calificación que no tolera errores graves, aunque sí permita algunos pequeños.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788dcd68",
   "metadata": {},
   "source": [
    "### Coeficiente de determinación $R^2$\n",
    "\n",
    "En un modelo de regresión, una variable irrelevante es aquella que:\n",
    "\n",
    "- No tiene una relación real con la variable que queremos predecir, o\n",
    "\n",
    "- Aporta muy poca información nueva (ya está contenida en otras variables), o\n",
    "\n",
    "- Solo mejora mínimamente el ajuste por pura casualidad (ruido).\n",
    "\n",
    "Por ejemplo, si estás construyendo un modelo para predecir el precio de una casa y agregas como variable el número de letras en el nombre de la calle, probablemente no tenga ninguna relación real. Eso sería una variable irrelevante.\n",
    "\n",
    "El coeficiente de determinación, conocido como $R^2$, es una métrica que nos dice qué proporción de la variabilidad de la variable dependiente puede ser explicada por el modelo. Es especialmente útil en modelos de regresión, tanto simples como múltiples: $$R^2=1-\\frac{SS_{res}}{SS_{tot}}$$\n",
    "\n",
    "Un $R^2$ de 0.90, por ejemplo, indica que el modelo explica el 90% de la variabilidad de los datos. Sin embargo, un valor alto no siempre es garantía de un buen modelo: si hay muchas variables irrelevantes, el $R^2$ puede inflarse artificialmente.\n",
    "\n",
    "#### Ventajas de $R^2$\n",
    "\n",
    "- Muy intuitivo como medida de “bondad de ajuste”.\n",
    "\n",
    "- Útil para comparar el mismo modelo en diferentes versiones o con distintos datos.\n",
    "\n",
    "- Adimensional: no depende de las unidades del problema.\n",
    "\n",
    "#### Limitaciones de $R^2$\n",
    " \n",
    "- No penaliza la complejidad del modelo: si agregas más variables, aunque no aporten nada, el $R^2$  nunca disminuye. Esto puede dar una falsa sensación de mejora.\n",
    "\n",
    "- No siempre refleja un buen modelo predictivo. Un alto $R^2$ puede coexistir con predicciones pobres fuera de la muestra (sobreajuste).\n",
    "\n",
    "- No es una medida de causalidad, sólo de correlación en el contexto del ajuste.\n",
    "\n",
    "### $R^2$ ajustado ($R^2_{ajustado}$)\n",
    "\n",
    "Para corregir el problema de que el $R^2$ aumenta con cada variable añadida (incluso irrelevante), se usa el ajustado, que penaliza el uso de variables innecesarias. Su fórmula es:\n",
    "\n",
    "$$R^2_{ajustado}=1-(1-R^2)\\cdot\\frac{n-1}{n-p-1}$$\n",
    "\n",
    "#### ¿Qué hace el $R^2_{ajustado}$\n",
    "\n",
    "- **Disminuye** si se añaden variables que no aportan valor explicativo.\n",
    "\n",
    "- **Aumenta** solo si las nuevas variables realmente ayudan a mejorar el modelo.\n",
    "\n",
    "Esto lo hace especialmente útil para:\n",
    "\n",
    "- Comparar modelos con diferente número de variables.\n",
    "\n",
    "- Seleccionar variables en procesos de regresión múltiple.\n",
    "\n",
    "#### ¿Qué pasa si agregas variables irrelevantes a un modelo?\n",
    "\n",
    "Con el $R^2$ clásico siempre aumenta o se mantiene, aunque la nueva variable no ayude en nada. Esto da una falsa impresión de mejora, y puede llevar a modelos más complejos de lo necesario, que se ajustan bien a los datos de entrenamiento pero generalizan mal (overfitting).\n",
    "\n",
    "Con el $R^2_{ajustado}$ este valor disminuye si la nueva variable no aporta una mejora real en la capacidad predictiva del modelo. Solo aumenta si la variable realmente reduce el error de predicción más allá de lo que se esperaría por azar.\n",
    " \n",
    "**Una analogía útil**\n",
    "\n",
    "Supón que tienes un equipo de personas resolviendo un problema. Si cada nueva persona realmente ayuda, el rendimiento del equipo mejora. Pero si solo agregas personas que no aportan nada o solo estorban, el equipo no mejora o incluso empeora.\n",
    "\n",
    "El $R^2$ solo ve que tienes más personas, y siempre piensa que eso es bueno. El $R^2_{ajustado}$ evalúa si cada persona nueva realmente vale la pena. Si no ayuda, te baja la calificación.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b012dbaf",
   "metadata": {},
   "source": [
    "## Interpretación de los coeficientes\n",
    "\n",
    "Una de las grandes ventajas de la regresión lineal frente a modelos más complejos es su interpretabilidad.\n",
    "\n",
    "- En la regresión simple, el coeficiente $\\beta_1$ nos dice cuánto aumenta (o disminuye) $y$ por cada unidad de incremento en $x$.\n",
    "\n",
    "- En la regresión múltiple, cada coeficiente se interpreta condicionalmente; es decir, suponiendo que las demás variables se mantienen constantes.\n",
    "\n",
    "Este detalle es importante, especialmente si algunas variables están correlacionadas entre sí, lo que puede llevar a una interpretación errónea o a problemas de multicolinealidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2725843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "####################### Evaluación del modelo ##########################\n",
    "########################################################################\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def calcular_metricas(y_real, y_pred, n, p):\n",
    "    \"\"\"\n",
    "    Calcula MAE, MSE, RMSE, R2 y R2 ajustado.\n",
    "    \n",
    "    Parámetros:\n",
    "    - y_real: valores reales\n",
    "    - y_pred: valores predichos\n",
    "    - n: número de observaciones\n",
    "    - p: número de predictores (sin incluir el intercepto)\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_real, y_pred)\n",
    "    mse = mean_squared_error(y_real, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_real, y_pred)\n",
    "    r2_ajustado = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "    \n",
    "    return pd.Series({\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R²\": r2,\n",
    "        \"R² ajustado\": r2_ajustado\n",
    "    })\n",
    "\n",
    "\n",
    "# Predicciones en entrenamiento\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "metricas_entrenamiento = calcular_metricas(y_train, y_train_pred, n=len(y_train), p=X_train.shape[1])\n",
    "\n",
    "# Predicciones en prueba\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "metricas_prueba = calcular_metricas(y_test, y_test_pred, n=len(y_test), p=X_test.shape[1])\n",
    "\n",
    "# Mostrar resultados\n",
    "metricas_df = pd.DataFrame({\n",
    "    \"Entrenamiento\": metricas_entrenamiento,\n",
    "    \"Prueba\": metricas_prueba\n",
    "})\n",
    "\n",
    "metricas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc5a9cb",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "La regresión lineal sigue siendo una herramienta poderosa y accesible dentro del repertorio de técnicas de machine learning. Si bien su simplicidad impone límites, esa misma simplicidad la convierte en una excelente herramienta didáctica y de exploración preliminar. Comprender su funcionamiento, interpretación y evaluación es esencial para cualquier persona que aspire a trabajar en ciencia de datos, estadística o inteligencia artificial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
