{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8bfa31a",
   "metadata": {},
   "source": [
    "![imagenes](logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531373e",
   "metadata": {},
   "source": [
    "# El papel fundamental de los conjuntos de entrenamiento y prueba en Machine Learning\n",
    "\n",
    "\n",
    "Imagina que vas a evaluar el desempeño de un alumno en cierta materia escolar mediante un examen de 10 preguntas, proporcionando un cuestionario para que estudie. Si las 10 preguntas del examen están en el cuestionario, es obvio que el alumno tendrá una muy buena nota, pero esto puede deberse a que simplemente memorizó el cuestionario. En cambio, si el examen está formado por preguntas parecidas, pero no iguales, a las del cuestionario, la calificación reflejará con mayor exactitud si el alumno realmente estudió, aprendió o solamente memorízó.\n",
    "\n",
    "Una de las ideas más fundamentales —y a menudo mal comprendidas— del aprendizaje automático es la necesidad de separar los datos en distintos subconjuntos para construir y evaluar modelos predictivos. Este capítulo está dedicado a explorar por qué hacemos esto, cómo se realiza correctamente, y qué implicaciones tiene para la calidad de nuestros modelos.\n",
    "\n",
    "Cuando entrenamos un modelo de machine learning, lo que realmente hacemos es encontrar una función matemática (una línea, un plano, un árbol de decisiones, una red neuronal, etc.) que se ajuste a un conjunto de datos. Esa función es ajustada para minimizar una medida de error, como el error cuadrático medio (MSE), usando los datos disponibles.\n",
    "\n",
    "Si luego evaluamos el desempeño del modelo utilizando ese mismo conjunto de datos, el modelo parecerá funcionar muy bien. Pero esto es una ilusión peligrosa: el modelo no solo ha aprendido los patrones reales en los datos, sino que también puede haber memorizado aspectos particulares del conjunto de entrenamiento, incluyendo ruido, errores o peculiaridades específicas. Esto es lo que se conoce como sobreajuste (overfitting).\n",
    "\n",
    "La consecuencia es clara: aunque el modelo se desempeñe maravillosamente en los datos que ya ha visto, podría fallar estrepitosamente al enfrentarse a nuevos datos. Por eso, necesitamos simular ese escenario de \"datos nuevos\" y medir cómo se comporta el modelo en él."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c0cd78",
   "metadata": {},
   "source": [
    "## Entrenamiento y prueba: la estrategia básica\n",
    "\n",
    "Para enfrentar este problema, la práctica estándar en machine learning consiste en dividir el conjunto total de datos en al menos dos subconjuntos:\n",
    "\n",
    "**Conjunto de entrenamiento (training set):** es el subconjunto de datos que se utiliza para ajustar los parámetros del modelo. Aquí es donde el modelo aprende.\n",
    "\n",
    "**Conjunto de prueba (test set):** es el subconjunto que se mantiene completamente separado y se utiliza exclusivamente para evaluar el rendimiento final del modelo.\n",
    "\n",
    "Esta separación debe hacerse antes de entrenar el modelo, y debe mantenerse inviolable: jamás se deben usar los datos de prueba para ajustar el modelo. Solo así podemos obtener una estimación honesta de su capacidad de generalización.\n",
    "\n",
    "![imagenes](im008.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951acc29",
   "metadata": {},
   "source": [
    "# Entrenamiento\n",
    "\n",
    "Durante el entrenamiento, el modelo utiliza los datos disponibles para ajustar sus parámetros internos. En una regresión lineal, por ejemplo, esto significa encontrar los coeficientes de la recta que minimizan el error cuadrático medio sobre el conjunto de entrenamiento. En una red neuronal, significa ajustar los pesos sinápticos mediante retropropagación. En todos los casos, el objetivo es el mismo: reducir el error de predicción en los datos conocidos.\n",
    "\n",
    "Pero aquí está la trampa: el objetivo del entrenamiento no es predecir bien los datos de entrenamiento, sino predecir bien datos que el modelo nunca ha visto. Entrenar bien no garantiza generalizar bien."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de765960",
   "metadata": {},
   "source": [
    "## Evaluación: la prueba del mundo real\n",
    "\n",
    "Después de entrenar, llega el momento crucial: probar el modelo. Esto se hace usando el conjunto de prueba. Como este subconjunto nunca fue utilizado durante el entrenamiento, representa un escenario más realista: así será el comportamiento del modelo cuando lo pongamos en producción, enfrentando nuevos casos.\n",
    "\n",
    "La evaluación se realiza midiendo alguna métrica de error o desempeño, como el RMSE, MAE, o el coeficiente de determinación $R^2$. Si el modelo obtiene un bajo error en el conjunto de prueba, es señal de que ha aprendido bien los patrones subyacentes de los datos. Si, en cambio, el error es mucho mayor que en el conjunto de entrenamiento, probablemente el modelo se ha sobreajustado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d05f37",
   "metadata": {},
   "source": [
    "## Sobreajuste y subajuste\n",
    "\n",
    "Esta tensión entre ajustar y generalizar es una de las piedras angulares del aprendizaje automático. Los modelos pueden caer en uno de dos extremos:\n",
    "\n",
    "- **Sobreajuste (overfitting):** el modelo se ajusta demasiado a los datos de entrenamiento, incluyendo el ruido. Tiene bajo error en entrenamiento pero alto error en prueba. Es como un estudiante que memoriza todas las respuestas del examen de práctica, pero no entiende el tema.\n",
    "\n",
    "- **Subajuste (underfitting):** el modelo es demasiado simple para capturar los patrones reales. Tiene alto error tanto en entrenamiento como en prueba. Es como un estudiante que no estudió lo suficiente y falla incluso en las preguntas que ya había visto.\n",
    "\n",
    "El objetivo es encontrar un punto intermedio: un modelo suficientemente complejo para aprender, pero suficientemente general para no memorizar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65253e8",
   "metadata": {},
   "source": [
    "## ¿Cómo dividir los datos?\n",
    "\n",
    "La división típica es entre un 70% u 80% para entrenamiento, y un 20% o 30% para prueba. Esta proporción puede variar dependiendo del tamaño del conjunto total. \n",
    "\n",
    "Si se dispone de muy pocos datos, usar una sola partición puede ser arriesgado. En esos casos, se recomienda usar técnicas como la validación cruzada, donde el conjunto de prueba rota, o el bootstrap, que crea muestras con reemplazo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfc4b37",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "Separar los datos en entrenamiento y prueba no es una formalidad: es un principio esencial para construir modelos que funcionen en el mundo real. Evaluar un modelo en los mismos datos con los que fue entrenado es como medir la eficacia de una medicina usando pacientes que no tomaron la medicina: los resultados serán engañosos y peligrosos.\n",
    "\n",
    "La generalización es el verdadero objetivo del aprendizaje automático, y sin una evaluación honesta, no podemos saber si la hemos alcanzado.\n",
    "\n",
    "Por eso, todo modelo bien construido debe ser evaluado rigurosamente en un conjunto de datos que no haya visto nunca antes, y de preferencia, bajo condiciones que simulen lo más fielmente posible su uso en la práctica.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
