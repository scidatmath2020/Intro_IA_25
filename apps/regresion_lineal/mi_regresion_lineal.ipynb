{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YkvTHaEmW-Y"
      },
      "outputs": [],
      "source": [
        "########################################################################\n",
        "#################### Carga de módulos de Python ########################\n",
        "########################################################################\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from plotnine import *\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################################################################\n",
        "############ Lectura de archivo y preprocesamiento de datos ############\n",
        "########################################################################\n",
        "\n",
        "mi_tabla = pd.read_csv(\"mpg.csv\")\n",
        "\n",
        "dataset = mi_tabla.select_dtypes(np.number)\n",
        "dataset.columns"
      ],
      "metadata": {
        "id": "R318TOMwmh94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###### Supongamos que la columna objetivo se llama Co y las variables independientes se llaman C1,C2,...,Cn.\n",
        "\n",
        "## Variable objetivo\n",
        "nombre_variable_objetivo = \"mpg\"\n",
        "objetivo = dataset[nombre_variable_objetivo]\n",
        "\n",
        "## Variable(s) independiente(s)\n",
        "variables_independientes = dataset[[\"horsepower\",\"weight\",\"displacement\",\"aceleration\"]]\n",
        "nombre_variables_independientes = variables_independientes.columns\n",
        "nombre_variables_independientes"
      ],
      "metadata": {
        "id": "5hLPM7LCmwcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################################################################\n",
        "########################   Ajuste del modelo   #########################\n",
        "########################################################################\n",
        "\n",
        "####### División en entrenamiento y prueba con 20% de prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(variables_independientes, objetivo, test_size=0.2,random_state=42)\n",
        "\n",
        "# Construye el pipeline\n",
        "pipeline = Pipeline([\n",
        "    (\"imputacion\", SimpleImputer(strategy=\"mean\")),\n",
        "    (\"modelo\", LinearRegression())\n",
        "])\n",
        "\n",
        "# Entrena el modelo con X_train y y_train\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Extrae el modelo entrenado (etapa final del pipeline)\n",
        "mi_modelo = pipeline.named_steps[\"modelo\"]\n",
        "\n",
        "coeficientes = pd.DataFrame({\n",
        "    \"Variable\": [\"Intercepto\"] + list(variables_independientes.columns),\n",
        "    \"Coeficiente\": [mi_modelo.intercept_] + list(mi_modelo.coef_)\n",
        "})\n",
        "\n",
        "print(coeficientes)"
      ],
      "metadata": {
        "id": "v0AKARlgnFIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################################################################\n",
        "##########################   Modelo final   ############################\n",
        "########################################################################\n",
        "\n",
        "texto_modelo = f\"{nombre_variable_objetivo} predicho = {coeficientes.Coeficiente[0]:.3f}\"\n",
        "\n",
        "for x in range(1,coeficientes.shape[0]):\n",
        "    signo = \" + \" if coeficientes.Coeficiente[x] >= 0 else \" - \"\n",
        "    texto_modelo = texto_modelo + f\"{signo}{np.abs(coeficientes.Coeficiente[x]):.3f} {coeficientes.Variable[x]}\"\n",
        "\n",
        "print(f\"El modelo es\\n\\n {texto_modelo}\")"
      ],
      "metadata": {
        "id": "GC8WRcQgnSTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_reales = dataset[[nombre_variables_independientes[0],nombre_variable_objetivo]]\n",
        "\n",
        "(ggplot(data=datos_reales) +\n",
        "    geom_point(mapping=aes(x=datos_reales.columns[0],y=datos_reales.columns[1]),color=\"blue\") +\n",
        "    geom_smooth(mapping=aes(x=datos_reales.columns[0],y=datos_reales.columns[1]),method=\"lm\",color=\"red\",se=False)\n",
        ")"
      ],
      "metadata": {
        "id": "n8uV8BRsnYYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################################################################\n",
        "####################### Evaluación del modelo ##########################\n",
        "########################################################################\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "def calcular_metricas(y_real, y_pred, n, p):\n",
        "    \"\"\"\n",
        "    Calcula MAE, MSE, RMSE, R2 y R2 ajustado.\n",
        "\n",
        "    Parámetros:\n",
        "    - y_real: valores reales\n",
        "    - y_pred: valores predichos\n",
        "    - n: número de observaciones\n",
        "    - p: número de predictores (sin incluir el intercepto)\n",
        "    \"\"\"\n",
        "    mae = mean_absolute_error(y_real, y_pred)\n",
        "    mse = mean_squared_error(y_real, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_real, y_pred)\n",
        "    r2_ajustado = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "\n",
        "    return pd.Series({\n",
        "        \"MAE\": mae,\n",
        "        \"MSE\": mse,\n",
        "        \"RMSE\": rmse,\n",
        "        \"R²\": r2,\n",
        "        \"R² ajustado\": r2_ajustado\n",
        "    })\n",
        "\n",
        "\n",
        "# Predicciones en entrenamiento\n",
        "y_train_pred = pipeline.predict(X_train)\n",
        "metricas_entrenamiento = calcular_metricas(y_train, y_train_pred, n=len(y_train), p=X_train.shape[1])\n",
        "\n",
        "# Predicciones en prueba\n",
        "y_test_pred = pipeline.predict(X_test)\n",
        "metricas_prueba = calcular_metricas(y_test, y_test_pred, n=len(y_test), p=X_test.shape[1])\n",
        "\n",
        "# Mostrar resultados\n",
        "metricas_df = pd.DataFrame({\n",
        "    \"Entrenamiento\": metricas_entrenamiento,\n",
        "    \"Prueba\": metricas_prueba\n",
        "})\n",
        "\n",
        "metricas_df"
      ],
      "metadata": {
        "id": "7vjmwASynwzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Supongamos que queremos hallar las predicciones en la tabla mis_nuevos_datos.csv\n",
        "\n",
        "columnas_entrenamiento = list(variables_independientes.columns)\n",
        "nuevos_datos = pd.read_csv(\"mpg_desconocidos.csv\")\n",
        "nuevos_datos[columnas_entrenamiento]"
      ],
      "metadata": {
        "id": "f_zR3fKInyRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predecir_nuevos_datos(modelo_pipeline, nuevos_datos, columnas_entrenamiento):\n",
        "    \"\"\"\n",
        "    Realiza predicciones sobre nuevos datos usando un modelo entrenado.\n",
        "\n",
        "    Parámetros:\n",
        "    - modelo_pipeline: objeto de modelo entrenado.\n",
        "    - nuevos_datos: DataFrame con los nuevos casos a predecir.\n",
        "    - columnas_entrenamiento: lista con los nombres de columnas usadas para entrenar el modelo.\n",
        "\n",
        "    Devuelve:\n",
        "    - Un array con las predicciones.\n",
        "    \"\"\"\n",
        "    # Verifica si faltan columnas\n",
        "    columnas_faltantes = set(columnas_entrenamiento) - set(nuevos_datos.columns)\n",
        "    if columnas_faltantes:\n",
        "        raise ValueError(f\"Faltan columnas necesarias: {columnas_faltantes}\")\n",
        "\n",
        "    # Verifica si hay columnas adicionales\n",
        "    columnas_adicionales = set(nuevos_datos.columns) - set(columnas_entrenamiento)\n",
        "    if columnas_adicionales:\n",
        "        print(f\"Advertencia: se ignorarán columnas adicionales: {columnas_adicionales}\")\n",
        "\n",
        "    # Reordenar columnas para que coincidan con el modelo\n",
        "    nuevos_datos_ordenado = nuevos_datos[columnas_entrenamiento]\n",
        "\n",
        "    # Realizar predicción\n",
        "    return modelo_pipeline.predict(nuevos_datos_ordenado)\n",
        "\n",
        "predicciones_nuevos_datos = predecir_nuevos_datos(pipeline, nuevos_datos, columnas_entrenamiento)\n",
        "predicciones_df = pd.DataFrame(predicciones_nuevos_datos, columns=[\"Predicción\"])\n",
        "nuevos_con_prediccion = pd.concat([nuevos_datos.reset_index(drop=True), predicciones_df], axis=1)\n",
        "\n",
        "# Mostrar resultado\n",
        "nuevos_con_prediccion"
      ],
      "metadata": {
        "id": "6XZP2Cmwn5z_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}